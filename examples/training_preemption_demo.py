"""
RLHF è§’è‰²è°ƒåº¦æŠ¢å  Demoï¼ˆCPU æœ¬åœ°æ¨¡æ‹Ÿï¼‰ã€‚

æ¼”ç¤ºçœŸå®çš„ RLHF è®­ç»ƒåœºæ™¯ä¸­çš„è§’è‰²ååŒä¸æŠ¢å ï¼š
1. Rollout è§’è‰²å¯åŠ¨ï¼Œè´Ÿè´£ç”Ÿæˆæ ·æœ¬æ•°æ®
2. Reward è§’è‰²åˆ°è¾¾ï¼Œéœ€è¦è¯„ä¼°æ ·æœ¬è´¨é‡ï¼Œå¯ä»¥æŠ¢å  Rollout
3. Train è§’è‰²åˆ°è¾¾ï¼Œéœ€è¦æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œå¯ä»¥æŠ¢å  Reward å’Œ Rollout
4. å±•ç¤ºä¸åŒè§’è‰²çš„ä¼˜å…ˆçº§å…³ç³»å’Œèµ„æºåˆ†é…

RLHF è§’è‰²è¯´æ˜ï¼š
- Trainï¼ˆè®­ç»ƒå™¨ï¼‰ï¼šæœ€é«˜ä¼˜å…ˆçº§ï¼Œè´Ÿè´£æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œéœ€è¦å¤§é‡è®¡ç®—èµ„æº
- Rewardï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œè´Ÿè´£è¯„ä¼°ç”Ÿæˆè´¨é‡ï¼Œéœ€è¦ä¸­ç­‰è®¡ç®—èµ„æº
- Rolloutï¼ˆé‡‡æ ·å™¨ï¼‰ï¼šè¾ƒä½ä¼˜å…ˆçº§ï¼Œè´Ÿè´£ç”Ÿæˆæ ·æœ¬æ•°æ®ï¼Œèµ„æºéœ€æ±‚ç›¸å¯¹çµæ´»
- Criticï¼ˆè¯„è®ºå™¨ï¼‰ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œè´Ÿè´£ä»·å€¼ä¼°è®¡

æ ¸å¿ƒç‰¹æ€§ï¼š
- âœ… åŸºäº label çš„è§’è‰²æŠ¢å ï¼ˆtrain > reward > rolloutï¼‰
- âœ… çœŸå®çš„ RLHF è®­ç»ƒè§’è‰²æ¨¡æ‹Ÿ
- âœ… ä¸åŒè§’è‰²çš„èµ„æºéœ€æ±‚å·®å¼‚
- âœ… æ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤æœºåˆ¶
- âœ… å®Œå…¨ CPU æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ GPU

è¿è¡Œæ–¹å¼ï¼š
    python examples/training_preemption_demo.py

Ray å‚æ•°ï¼š
- local_mode=True: è¿›ç¨‹å†…æ‰§è¡Œï¼Œä¾¿äºè°ƒè¯•
- num_cpus=4: é™åˆ¶ CPU æ ¸å¿ƒæ•°
- ignore_reinit_error=True: å¿½ç•¥é‡å¤åˆå§‹åŒ–
"""

from __future__ import annotations

import math
import random
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import ray

# ç¡®ä¿èƒ½å¤Ÿç›´æ¥ä½¿ç”¨æºç ä¸­çš„ schedulemesh
REPO_ROOT = Path(__file__).resolve().parent.parent
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from schedulemesh.config.policy import PreemptionAggressiveness

from schedulemesh.core.agents import MetricsReportingAgent
from schedulemesh.core.controllers.ray_scheduler import RayScheduler


@dataclass
class RLHFRoleConfig:
    """RLHF è§’è‰²é…ç½®"""
    role: str  # train, reward, rollout, critic
    model_size: str  # 7B, 13B, 70B
    batch_size: int
    learning_rate: float
    gpu_required: float
    cpu_required: float
    memory_required: float  # GB


@dataclass
class RoleStep:
    """RLHF è§’è‰²æ‰§è¡Œæ­¥éª¤"""
    step: int
    metric_value: float  # æ ¹æ®è§’è‰²ä¸åŒï¼šrewardåˆ†æ•°ã€lossã€æ ·æœ¬æ•°ç­‰
    loss: float
    resource_utilization: float  # 0.0 - 1.0
    throughput: float  # tokens/sec æˆ– samples/sec
    timestamp: float


@ray.remote
class RLHFRoleAgentActor(MetricsReportingAgent):
    """
    æ¨¡æ‹ŸçœŸå®çš„ RLHF è§’è‰² Agentï¼Œæ”¯æŒèµ„æºç®¡ç†å’Œæ£€æŸ¥ç‚¹ä¿å­˜ã€‚

    ç‰¹æ€§ï¼š
    - æ”¯æŒä¸åŒ RLHF è§’è‰²ï¼ˆtrainã€rewardã€rolloutã€criticï¼‰
    - æ¨¡æ‹Ÿ GPU/CPU/å†…å­˜èµ„æºä½¿ç”¨
    - æ”¯æŒæ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤
    - æ¨¡æ‹ŸçœŸå®çš„è§’è‰²å·¥ä½œè´Ÿè½½å’Œèµ„æºåˆ©ç”¨ç‡
    """

    def __init__(
        self,
        name: str,
        labels: Dict[str, str],
        supervisor: Optional[ray.actor.ActorHandle] = None,
        *,
        report_interval: float = 1.0,
    ):
        super().__init__(
            name,
            labels,
            supervisor,
            report_interval=report_interval,
            max_pending_reports=64,
        )
        
        # ä» Ray çš„èµ„æºé…ç½®ä¸­è·å–èµ„æºä¿¡æ¯
        try:
            # è·å–å½“å‰ actor çš„èµ„æºé™åˆ¶
            resource_limits = ray.get_resource_limits()
            self.resources = {
                "cpu": resource_limits.get("CPU", 2.0),
                "memory": resource_limits.get("memory", 4096.0),
                "gpu": resource_limits.get("GPU", 1.0),
            }
        except Exception:
            # å¦‚æœæ— æ³•è·å–èµ„æºé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
            self.resources = {"cpu": 2.0, "memory": 4096.0, "gpu": 1.0}
        
        # å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ
        self.resource_usage = {"cpu": 0.0, "memory": 0.0, "gpu": 0.0}

        self._tasks: Dict[str, Dict[str, Any]] = {}
        self._task_threads: Dict[str, threading.Thread] = {}
        self._stop_flags: Dict[str, threading.Event] = {}
        self._lock = threading.Lock()
        
        print(f"ğŸ“¦ RLHFRoleAgent '{name}' åˆå§‹åŒ– | èµ„æºé…é¢: {self.resources}")

    # ---- èµ„æºç®¡ç† ---------------------------------------------------------
    
    def get_available_resources(self) -> dict:
        """è·å–å¯ç”¨èµ„æº"""
        with self._lock:
            available = {
                res: total - self.resource_usage.get(res, 0.0)
                for res, total in self.resources.items()
            }
        return {"success": True, "available": available, "total": self.resources}
    
    def _allocate_resources(self, config: RLHFRoleConfig) -> bool:
        """å°è¯•åˆ†é…èµ„æº"""
        with self._lock:
            # æ£€æŸ¥èµ„æºæ˜¯å¦è¶³å¤Ÿ
            required = {
                "cpu": config.cpu_required,
                "memory": config.memory_required,
                "gpu": config.gpu_required,
            }
            for res, amount in required.items():
                available = self.resources.get(res, 0.0) - self.resource_usage.get(res, 0.0)
                if available < amount:
                    return False
            
            # åˆ†é…èµ„æº
            for res, amount in required.items():
                self.resource_usage[res] = self.resource_usage.get(res, 0.0) + amount
            return True
    
    def _release_resources(self, config: RLHFRoleConfig) -> None:
        """é‡Šæ”¾èµ„æº"""
        with self._lock:
            self.resource_usage["cpu"] = max(0.0, self.resource_usage.get("cpu", 0.0) - config.cpu_required)
            self.resource_usage["memory"] = max(0.0, self.resource_usage.get("memory", 0.0) - config.memory_required)
            self.resource_usage["gpu"] = max(0.0, self.resource_usage.get("gpu", 0.0) - config.gpu_required)

    # ---- RLHF è§’è‰²ä»»åŠ¡æ¨¡æ‹Ÿ ---------------------------------------------------------

    def start_role_task(
        self,
        task_id: str,
        config: RLHFRoleConfig,
        *,
        steps: int = 100,
        step_duration: float = 0.15,
        checkpoint_interval: int = 10,
    ) -> dict:
        """
        å¯åŠ¨ RLHF è§’è‰²ä»»åŠ¡ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰ã€‚

        Args:
            task_id: ä»»åŠ¡æ ‡è¯†
            config: è§’è‰²é…ç½®ï¼ˆåŒ…å«èµ„æºéœ€æ±‚ï¼‰
            steps: æ‰§è¡Œæ€»æ­¥æ•°
            step_duration: æ¯æ­¥è€—æ—¶ï¼ˆç§’ï¼‰
            checkpoint_interval: æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”
        """
        # æ£€æŸ¥å¹¶åˆ†é…èµ„æº
        if not self._allocate_resources(config):
            return {
                "success": False,
                "error": "Insufficient resources",
                "required": {
                    "cpu": config.cpu_required,
                    "memory": config.memory_required,
                    "gpu": config.gpu_required,
                },
                "available": self.get_available_resources()["available"],
            }
        
        stop_flag = threading.Event()
        role_steps: List[RoleStep] = []
        checkpoints: List[int] = []
        
        summary = {
            "task_id": task_id,
            "config": config.__dict__,
            "status": "running",
            "start_time": time.time(),
            "steps": role_steps,
            "checkpoints": checkpoints,
            "total_metric": 0.0,
            "avg_throughput": 0.0,
        }

        with self._lock:
            if task_id in self._tasks:
                self._release_resources(config)
                return {"success": False, "error": f"Task '{task_id}' already running"}
            self._tasks[task_id] = summary
            self._stop_flags[task_id] = stop_flag

        def _run_role_task():
            total_metric = 0.0
            total_throughput = 0.0
            
            # æ ¹æ® RLHF è§’è‰²è°ƒæ•´åŸºç¡€å‚æ•°
            if config.role == "train":
                # Train: è®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦æœ€å¤šèµ„æºï¼Œè¾“å‡ºloss
                base_metric = 0.5  # åˆå§‹loss
                exploration = 0.1
                base_throughput = 2000.0  # tokens/sec
                resource_util_base = 0.95
                metric_name = "loss"
            elif config.role == "reward":
                # Reward: è¯„ä¼°æ ·æœ¬è´¨é‡ï¼Œè¾“å‡ºrewardåˆ†æ•°
                base_metric = 0.6  # åˆå§‹rewardåˆ†æ•°
                exploration = 0.15
                base_throughput = 3000.0  # samples/sec
                resource_util_base = 0.85
                metric_name = "reward_score"
            elif config.role == "rollout":
                # Rollout: ç”Ÿæˆæ ·æœ¬æ•°æ®ï¼Œèµ„æºéœ€æ±‚ç›¸å¯¹çµæ´»
                base_metric = 0.7  # åˆå§‹ç”Ÿæˆè´¨é‡
                exploration = 0.1
                base_throughput = 5000.0  # samples/sec
                resource_util_base = 0.75
                metric_name = "generation_quality"
            elif config.role == "critic":
                # Critic: ä»·å€¼ä¼°è®¡
                base_metric = 0.6
                exploration = 0.12
                base_throughput = 3500.0
                resource_util_base = 0.80
                metric_name = "value_estimate"
            else:
                base_metric = 0.5
                exploration = 0.1
                base_throughput = 4000.0
                resource_util_base = 0.8
                metric_name = "metric"
            
            for step_idx in range(1, steps + 1):
                if stop_flag.is_set():
                    summary["status"] = "preempted"
                    break

                time.sleep(step_duration)
                
                # æ¨¡æ‹Ÿè§’è‰²æŒ‡æ ‡
                decay = math.exp(-step_idx / max(steps, 1))
                metric_value = base_metric + (1 - base_metric) * (1 - decay)
                metric_value += random.uniform(-exploration, exploration)
                metric_value = max(0.0, min(1.0, metric_value))
                
                # loss éšç€è®­ç»ƒä¸‹é™
                loss = max(0.0, 1.5 * (1 - metric_value) + random.uniform(-0.05, 0.05))
                
                # æ¨¡æ‹Ÿèµ„æºåˆ©ç”¨ç‡
                resource_util = resource_util_base + random.uniform(-0.05, 0.05)
                resource_util = max(0.0, min(1.0, resource_util))
                
                # æ¨¡æ‹Ÿååé‡
                throughput = base_throughput * (config.batch_size / 32.0) * resource_util
                throughput += random.uniform(-200, 200)
                throughput = max(0.0, throughput)

                total_metric += metric_value
                total_throughput += throughput
                
                self.report_metrics(
                    {
                        "role": config.role,
                        "current_step": step_idx,
                        "loss": loss,
                        metric_name: metric_value,
                        "throughput": throughput,
                        "resource_utilization": resource_util,
                    }
                )
                role_steps.append(
                    RoleStep(
                        step=step_idx,
                        metric_value=metric_value,
                        loss=loss,
                        resource_utilization=resource_util,
                        throughput=throughput,
                        timestamp=time.time(),
                    )
                )
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if step_idx % checkpoint_interval == 0:
                    checkpoints.append(step_idx)

            else:
                summary["status"] = "completed"

            summary["end_time"] = time.time()
            summary["total_metric"] = total_metric
            summary["avg_throughput"] = total_throughput / max(len(role_steps), 1)
            
            final_metrics = {
                "role": config.role,
                "current_step": len(role_steps),
                "status": summary.get("status", "running"),
                "total_metric": summary["total_metric"],
                "avg_throughput": summary["avg_throughput"],
            }
            if role_steps:
                final_metrics["loss"] = role_steps[-1].loss
                final_metrics[metric_name] = role_steps[-1].metric_value
                final_metrics["throughput"] = role_steps[-1].throughput
            self.report_metrics(final_metrics, force=True)
            
            # é‡Šæ”¾èµ„æº
            self._release_resources(config)
            self.flush_metrics()

        worker = threading.Thread(target=_run_role_task, name=f"role-{task_id}", daemon=True)
        with self._lock:
            self._task_threads[task_id] = worker
        worker.start()
        
        print(
            f"ğŸš€ å¯åŠ¨ RLHF è§’è‰²ä»»åŠ¡ '{task_id}' | "
            f"è§’è‰²={config.role} æ¨¡å‹={config.model_size} "
            f"èµ„æº=[GPU:{config.gpu_required}, CPU:{config.cpu_required}, "
            f"MEM:{config.memory_required}GB]"
        )
        return {"success": True, "task_id": task_id}

    def cancel(self, task_id: str) -> dict:
        """åœæ­¢æŒ‡å®šè§’è‰²ä»»åŠ¡ï¼Œä¿å­˜æ£€æŸ¥ç‚¹å¹¶è¿”å›ä»»åŠ¡æ‘˜è¦ã€‚"""
        with self._lock:
            stop_flag = self._stop_flags.get(task_id)
            summary = self._tasks.get(task_id)
            thread = self._task_threads.get(task_id)

        if stop_flag is None or summary is None:
            return {"success": False, "error": f"Task '{task_id}' not found"}

        print(f"â¸ï¸  å–æ¶ˆè§’è‰²ä»»åŠ¡ '{task_id}'ï¼Œä¿å­˜æ£€æŸ¥ç‚¹...")
        stop_flag.set()
        if thread and thread.is_alive():
            thread.join(timeout=2.0)

        with self._lock:
            self._stop_flags.pop(task_id, None)
            self._task_threads.pop(task_id, None)

        summary.setdefault("end_time", time.time())
        summary.setdefault("status", "preempted")
        
        # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
        if summary.get("steps"):
            last_step = len(summary["steps"])
            if last_step not in summary.get("checkpoints", []):
                summary.setdefault("checkpoints", []).append(last_step)
        
        print(
            f"ğŸ’¾ ä»»åŠ¡ '{task_id}' å·²ä¿å­˜æ£€æŸ¥ç‚¹: "
            f"step={len(summary.get('steps', []))} "
            f"checkpoints={summary.get('checkpoints', [])}"
        )
        return {"success": True, "task": summary}

    def role_task_summary(self, task_id: Optional[str] = None) -> dict:
        """è¿”å›æŒ‡å®šä»»åŠ¡æˆ–å…¨éƒ¨ä»»åŠ¡çš„å½“å‰çŠ¶æ€ã€‚"""
        with self._lock:
            if task_id:
                task = self._tasks.get(task_id)
                if task is None:
                    return {"success": False, "error": f"Task '{task_id}' not found"}
                return {
                    "success": True,
                    "task": {
                        **task,
                        "steps": [step.__dict__ for step in task["steps"]],
                    },
                }

            return {
                "success": True,
                "tasks": {
                    tid: {
                        **summary,
                        "steps": [step.__dict__ for step in summary["steps"]],
                    }
                    for tid, summary in self._tasks.items()
                },
            }


def _print_header(title: str) -> None:
    print("\n" + title)
    print("-" * len(title))


def run_demo() -> None:
    print("=" * 80)
    print("ğŸš€ RLHF è§’è‰²è°ƒåº¦æŠ¢å  Demoï¼ˆCPU æœ¬åœ°æ¨¡æ‹Ÿï¼‰")
    print("=" * 80)

    ray_config = {
        "ignore_reinit_error": True,
        "local_mode": True,  # è¿›ç¨‹å†…æ‰§è¡Œï¼Œä¾¿äºè°ƒè¯•
        "num_cpus": 4,      # é™åˆ¶ CPU æ ¸å¿ƒæ•°
        "include_dashboard": False,  # å…³é—­ dashboard
        "log_to_driver": False,     # å‡å°‘æ—¥å¿—è¾“å‡º
    }

    # æ™ºèƒ½åˆå§‹åŒ– Ray
    try:
        # å°è¯•è¿æ¥ç°æœ‰é›†ç¾¤
        ray.init(address="auto", ignore_reinit_error=True)
        print("âœ… è¿æ¥åˆ°ç°æœ‰ Ray é›†ç¾¤")
    except Exception:
        # åˆ›å»ºæ–°æœ¬åœ°é›†ç¾¤
        print(f"ğŸ“‹ Ray é…ç½®: {ray_config}")
        ray.init(**ray_config)
    scheduler = RayScheduler("rlhf-role-preemption-demo")

    def print_preemption_stats(title: str) -> None:
        stats = scheduler.get_preemption_stats()
        print(f"ğŸ“Š {title}")
        print(f"  å½“å‰è¿è¡Œä»»åŠ¡: {stats.get('running_tasks', 0)}")
        print(f"  ç´¯è®¡æŠ¢å æ¬¡æ•°: {stats.get('total_preemptions', 0)}")
        recent = stats.get("recent_preemptions") or []
        if recent:
            print("  æœ€è¿‘æŠ¢å è®°å½•:")
            for record in recent:
                task_id = record.get("task_id")
                pool = record.get("pool_name")
                reason = record.get("reason")
                cancel_success = record.get("cancel_success")
                print(
                    f"    - task={task_id} pool={pool} reason={reason} "
                    f"cancel_success={cancel_success}"
                )
        else:
            print("  æœ€è¿‘æŠ¢å è®°å½•: æ— ")

    try:
        print("ğŸ“‹ é…ç½®æŠ¢å ç­–ç•¥...")
        scheduler.update_preemption_policy(
            enable_label_preemption=True,
            label_preemption_rules={
                "role": {
                    "train": ["reward", "critic", "rollout"],
                    "reward": ["rollout"],
                    "critic": ["rollout"],
                }
            },
            preemption_aggressiveness=PreemptionAggressiveness.MEDIUM,
            cross_pool_priority_threshold=5.0,
            enable_cross_pool_preemption=True,
        )
        print("âœ… æŠ¢å ç­–ç•¥: Train > Reward/Critic > Rollout")

        pool_name = "rlhf-shared-pool"
        print(f"ğŸ—ï¸  åˆ›å»ºèµ„æºæ±  {pool_name} ...")
        scheduler.create_pool(
            name=pool_name,
            labels={"workload": "rlhf", "tier": "shared"},
            resources={"cpu": 2.0, "memory": 4096.0, "gpu": 0.0},
            target_agents=1,
        )
        print(f"  âœ… {pool_name}: 0x GPU, 2 CPU, 4GB Memory")

        active_agents: Dict[str, Dict[str, Any]] = {}

        def launch_role_task(
            *,
            task_id: str,
            config: RLHFRoleConfig,
            steps: int,
            step_duration: float,
            checkpoint_interval: int,
        ) -> Optional[Dict[str, Any]]:
            resources = {
                "cpu": config.cpu_required,
                "memory": config.memory_required,
                "gpu": config.gpu_required,
            }
            mem_gb = resources["memory"] / 1024.0 if resources["memory"] else 0.0
            print(f"{'=' * 80}")
            print(f"ğŸ¬ å¯åŠ¨è§’è‰²ä»»åŠ¡ {config.role.upper()} -> {task_id}")
            print(f"{'=' * 80}")
            print(f"æ¨¡å‹è§„æ¨¡: {config.model_size}")
            print(f"æ‰¹å¤§å°: {config.batch_size}")
            print(f"èµ„æºéœ€æ±‚: {resources['cpu']} CPU, {mem_gb:.1f} GB Memory")

            submission = scheduler.submit_task_with_preemption(
                task_id=task_id,
                pool_name=pool_name,
                resources=resources,
                priority=5.0,
                labels={
                    "job": "training",
                    "role": config.role,
                    "model_size": config.model_size,
                },
                actor_class=RLHFRoleAgentActor,
                actor_kwargs={
                    "supervisor": scheduler.supervisor_handle(),
                    "report_interval": 1.0,
                },
            )

            if not submission.get("success"):
                print(
                    f"âœ— ä»»åŠ¡æäº¤å¤±è´¥: {submission.get('error')} "
                    f"(reason={submission.get('reason')})"
                )
                return None

            agent_info = submission["agent"]
            active_agents[task_id] = agent_info
            scheduler.register_running_task(
                task_id=task_id,
                agent_name=agent_info["name"],
                pool_name=pool_name,
                priority=5.0,
                labels={
                    "job": "training",
                    "role": config.role,
                    "model_size": config.model_size,
                },
                estimated_duration=1200.0,
            )

            handle = agent_info["handle"]
            start_result = ray.get(
                handle.start_role_task.remote(
                    task_id=task_id,
                    config=config,
                    steps=steps,
                    step_duration=step_duration,
                    checkpoint_interval=checkpoint_interval,
                )
            )
            if start_result.get("success"):
                print(f"âœ“ ä»»åŠ¡å·²å¯åŠ¨ (agent={agent_info['name']})")
            else:
                print(f"âœ— ä»»åŠ¡å¯åŠ¨å¤±è´¥: {start_result.get('error')}")
            return agent_info

        rollout_task_id = "rollout-data-collection"
        rollout_config = RLHFRoleConfig(
            role="rollout",
            model_size="13B",
            batch_size=24,
            learning_rate=5e-5,
            gpu_required=0.0,
            cpu_required=2.0,
            memory_required=2048.0,
        )
        rollout_agent = launch_role_task(
            task_id=rollout_task_id,
            config=rollout_config,
            steps=90,
            step_duration=0.12,
            checkpoint_interval=15,
        )

        if rollout_agent:
            print("â³ Rollout è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 3 ç§’è§‚å¯Ÿ...")
            time.sleep(3.0)

        reward_task_id = "reward-model-eval"
        reward_config = RLHFRoleConfig(
            role="reward",
            model_size="13B",
            batch_size=16,
            learning_rate=1e-4,
            gpu_required=0.0,
            cpu_required=2.0,
            memory_required=2304.0,
        )
        reward_agent = launch_role_task(
            task_id=reward_task_id,
            config=reward_config,
            steps=80,
            step_duration=0.14,
            checkpoint_interval=12,
        )

        print_preemption_stats("Reward è§’è‰²æäº¤åçš„æŠ¢å ç»Ÿè®¡")

        if reward_agent:
            print("â³ Reward è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 2 ç§’è§‚å¯Ÿ...")
            time.sleep(2.0)

        if rollout_agent:
            try:
                ray.get(
                    rollout_agent["handle"].role_task_summary.remote(rollout_task_id)
                )
            except Exception:
                print("â„¹ï¸  Rollout ä»»åŠ¡å¥æŸ„å·²æ¸…ç†ï¼Œè¯´æ˜æŠ¢å æˆåŠŸã€‚")

        train_task_id = "rlhf-train-step"
        train_config = RLHFRoleConfig(
            role="train",
            model_size="7B",
            batch_size=32,
            learning_rate=2e-5,
            gpu_required=0.0,
            cpu_required=2.0,
            memory_required=3072.0,
        )
        train_agent = launch_role_task(
            task_id=train_task_id,
            config=train_config,
            steps=70,
            step_duration=0.16,
            checkpoint_interval=10,
        )

        print_preemption_stats("Train è§’è‰²æäº¤åçš„æŠ¢å ç»Ÿè®¡")

        if reward_agent:
            try:
                ray.get(
                    reward_agent["handle"].role_task_summary.remote(reward_task_id)
                )
            except Exception:
                print("â„¹ï¸  Reward ä»»åŠ¡å¥æŸ„å·²æ¸…ç†ï¼Œè¯´æ˜ Train æˆåŠŸæŠ¢å ã€‚")

        if train_agent:
            print("â³ Train è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 3 ç§’è§‚å¯Ÿ...")
            time.sleep(3.0)
            try:
                train_summary = ray.get(
                    train_agent["handle"].role_task_summary.remote(train_task_id)
                )
            except Exception as exc:
                print(f"âš ï¸  æ— æ³•è·å– Train ä»»åŠ¡è¿›åº¦: {exc}")
            else:
                if train_summary.get("success"):
                    task = train_summary["task"]
                    steps = task.get("steps", [])
                    if steps:
                        latest = steps[-1]
                        metric_label = task.get("metric_name", "metric_value")
                        print("ğŸ“Š Train è§’è‰²æœ€æ–°è¿›åº¦:")
                        print(f"  çŠ¶æ€: {task.get('status')}")
                        print(f"  å®Œæˆ step: {len(steps)}")
                        print(f"  {metric_label}: {latest.get('metric_value', 0):.4f}")
                        print(f"  loss: {latest.get('loss', 0):.4f}")
                        print(f"  ååé‡: {latest.get('throughput', 0):.0f} tokens/s")
                else:
                    print(f"âš ï¸  Train ä»»åŠ¡è¿›åº¦æŸ¥è¯¢å¤±è´¥: {train_summary.get('error')}")

        print(f"" + "=" * 80)
        print(f"ğŸ“ˆ Demo æ€»ç»“")
        print(f"=" * 80)
        print(f"âœ“ Rollout è§’è‰²é¦–å…ˆå ç”¨èµ„æºæ± ")
        print(f"âœ“ Reward è§’è‰²æ ¹æ® role label æŠ¢å  Rollout ä»»åŠ¡")
        print(f"âœ“ Train è§’è‰²è¿›ä¸€æ­¥æŠ¢å  Reward å¹¶ç»§ç»­è®­ç»ƒ")
        print(f"âœ“ get_preemption_stats() å±•ç¤ºæŠ¢å å†å²ä¸ç»Ÿè®¡æ•°æ®")
        print(f"âœ“ submit_task_with_preemption è‡ªåŠ¨ä¸²è”èµ„æºé¢„ç•™ã€æŠ¢å ä¸ Agent åˆ›å»º")

    finally:
        print("æ¸…ç† Ray / Scheduler")
        scheduler.shutdown()
        ray.shutdown()


if __name__ == "__main__":
    run_demo()
