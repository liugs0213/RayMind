"""
RLHF è§’è‰²è°ƒåº¦æŠ¢å  Demoï¼ˆä½¿ç”¨ SimpleSchedulerï¼‰

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆçš„ RLHF è®­ç»ƒåœºæ™¯æ¼”ç¤ºï¼Œä½¿ç”¨ SimpleScheduler API æ¥å±•ç¤ºï¼š
1. Rollout è§’è‰²å¯åŠ¨ï¼Œè´Ÿè´£ç”Ÿæˆæ ·æœ¬æ•°æ®
2. Reward è§’è‰²åˆ°è¾¾ï¼Œæ ¹æ®è§’è‰²æ ‡ç­¾æŠ¢å  Rollout
3. Train è§’è‰²åˆ°è¾¾ï¼ŒæŠ¢å  Reward å¹¶è·å¾—èµ„æº

RLHF è§’è‰²è¯´æ˜ï¼š
- Trainï¼ˆè®­ç»ƒå™¨ï¼‰ï¼šæœ€é«˜ä¼˜å…ˆçº§ï¼Œè´Ÿè´£æ›´æ–°æ¨¡å‹å‚æ•°
- Rewardï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œè´Ÿè´£è¯„ä¼°ç”Ÿæˆè´¨é‡
- Rolloutï¼ˆé‡‡æ ·å™¨ï¼‰ï¼šè¾ƒä½ä¼˜å…ˆçº§ï¼Œè´Ÿè´£ç”Ÿæˆæ ·æœ¬æ•°æ®
- Criticï¼ˆè¯„è®ºå™¨ï¼‰ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼Œè´Ÿè´£ä»·å€¼ä¼°è®¡

æ ¸å¿ƒç‰¹æ€§ï¼š
- âœ… ä½¿ç”¨ SimpleScheduler ç®€åŒ–çš„ API
- âœ… åŸºäº label çš„è§’è‰²æŠ¢å ï¼ˆtrain > reward > rolloutï¼‰
- âœ… è‡ªåŠ¨ä»»åŠ¡æ³¨å†Œå’ŒæŠ¢å å¤„ç†
- âœ… æ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤æœºåˆ¶
- âœ… å®Œå…¨ CPU æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ GPU

è¿è¡Œæ–¹å¼ï¼š
    python examples/simple_rlhf_preemption_demo.py
"""

from __future__ import annotations

import math
import random
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import ray

# ç¡®ä¿èƒ½å¤Ÿç›´æ¥ä½¿ç”¨æºç ä¸­çš„ schedulemesh
REPO_ROOT = Path(__file__).resolve().parent.parent
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from schedulemesh.simple import SimpleScheduler
from schedulemesh.config.policy import PreemptionAggressiveness


@dataclass
class RLHFRoleConfig:
    """RLHF è§’è‰²é…ç½®"""
    role: str  # train, reward, rollout, critic
    model_size: str  # 7B, 13B, 70B
    batch_size: int
    learning_rate: float
    cpu_required: float
    memory_required: float  # MB


@dataclass
class RoleStep:
    """RLHF è§’è‰²æ‰§è¡Œæ­¥éª¤"""
    step: int
    metric_value: float  # æ ¹æ®è§’è‰²ä¸åŒï¼šrewardåˆ†æ•°ã€lossã€æ ·æœ¬æ•°ç­‰
    loss: float
    resource_utilization: float  # 0.0 - 1.0
    throughput: float  # tokens/sec æˆ– samples/sec
    timestamp: float


@ray.remote
class RLHFRoleAgent:
    """
    ç®€åŒ–ç‰ˆçš„ RLHF è§’è‰² Agentï¼Œä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ã€‚

    ç‰¹æ€§ï¼š
    - æ”¯æŒä¸åŒ RLHF è§’è‰²ï¼ˆtrainã€rewardã€rolloutã€criticï¼‰
    - æ¨¡æ‹ŸçœŸå®çš„è§’è‰²å·¥ä½œè´Ÿè½½
    - æ”¯æŒæ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤
    """

    def __init__(self, name: str, labels: Dict[str, str]):
        self.name = name
        self.labels = labels
        self._tasks: Dict[str, Dict[str, Any]] = {}
        self._task_threads: Dict[str, threading.Thread] = {}
        self._stop_flags: Dict[str, threading.Event] = {}
        self._lock = threading.Lock()
        
        print(f"ğŸ“¦ RLHFRoleAgent '{name}' åˆå§‹åŒ– | æ ‡ç­¾: {labels}")

    def start_role_task(
        self,
        task_id: str,
        config: RLHFRoleConfig,
        *,
        steps: int = 100,
        step_duration: float = 0.15,
        checkpoint_interval: int = 10,
    ) -> dict:
        """
        å¯åŠ¨ RLHF è§’è‰²ä»»åŠ¡ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰ã€‚

        Args:
            task_id: ä»»åŠ¡æ ‡è¯†
            config: è§’è‰²é…ç½®ï¼ˆåŒ…å«èµ„æºéœ€æ±‚ï¼‰
            steps: æ‰§è¡Œæ€»æ­¥æ•°
            step_duration: æ¯æ­¥è€—æ—¶ï¼ˆç§’ï¼‰
            checkpoint_interval: æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”
        """
        stop_flag = threading.Event()
        role_steps: List[RoleStep] = []
        checkpoints: List[int] = []
        
        summary = {
            "task_id": task_id,
            "config": config.__dict__,
            "status": "running",
            "start_time": time.time(),
            "steps": role_steps,
            "checkpoints": checkpoints,
            "total_metric": 0.0,
            "avg_throughput": 0.0,
        }

        with self._lock:
            if task_id in self._tasks:
                return {"success": False, "error": f"Task '{task_id}' already running"}
            self._tasks[task_id] = summary
            self._stop_flags[task_id] = stop_flag

        def _run_role_task():
            total_metric = 0.0
            total_throughput = 0.0
            
            # æ ¹æ® RLHF è§’è‰²è°ƒæ•´åŸºç¡€å‚æ•°
            if config.role == "train":
                base_metric = 0.5  # åˆå§‹loss
                exploration = 0.1
                base_throughput = 2000.0  # tokens/sec
                resource_util_base = 0.95
                metric_name = "loss"
            elif config.role == "reward":
                base_metric = 0.6  # åˆå§‹rewardåˆ†æ•°
                exploration = 0.15
                base_throughput = 3000.0  # samples/sec
                resource_util_base = 0.85
                metric_name = "reward_score"
            elif config.role == "rollout":
                base_metric = 0.7  # åˆå§‹ç”Ÿæˆè´¨é‡
                exploration = 0.1
                base_throughput = 5000.0  # samples/sec
                resource_util_base = 0.75
                metric_name = "generation_quality"
            elif config.role == "critic":
                base_metric = 0.6
                exploration = 0.12
                base_throughput = 3500.0
                resource_util_base = 0.80
                metric_name = "value_estimate"
            else:
                base_metric = 0.5
                exploration = 0.1
                base_throughput = 4000.0
                resource_util_base = 0.8
                metric_name = "metric"
            
            for step_idx in range(1, steps + 1):
                if stop_flag.is_set():
                    summary["status"] = "preempted"
                    break

                time.sleep(step_duration)
                
                # æ¨¡æ‹Ÿè§’è‰²æŒ‡æ ‡
                decay = math.exp(-step_idx / max(steps, 1))
                metric_value = base_metric + (1 - base_metric) * (1 - decay)
                metric_value += random.uniform(-exploration, exploration)
                metric_value = max(0.0, min(1.0, metric_value))
                
                # loss éšç€è®­ç»ƒä¸‹é™
                loss = max(0.0, 1.5 * (1 - metric_value) + random.uniform(-0.05, 0.05))
                
                # æ¨¡æ‹Ÿèµ„æºåˆ©ç”¨ç‡
                resource_util = resource_util_base + random.uniform(-0.05, 0.05)
                resource_util = max(0.0, min(1.0, resource_util))
                
                # æ¨¡æ‹Ÿååé‡
                throughput = base_throughput * (config.batch_size / 32.0) * resource_util
                throughput += random.uniform(-200, 200)
                throughput = max(0.0, throughput)

                total_metric += metric_value
                total_throughput += throughput
                
                role_steps.append(
                    RoleStep(
                        step=step_idx,
                        metric_value=metric_value,
                        loss=loss,
                        resource_utilization=resource_util,
                        throughput=throughput,
                        timestamp=time.time(),
                    )
                )
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if step_idx % checkpoint_interval == 0:
                    checkpoints.append(step_idx)

            else:
                summary["status"] = "completed"

            summary["end_time"] = time.time()
            summary["total_metric"] = total_metric
            summary["avg_throughput"] = total_throughput / max(len(role_steps), 1)

        worker = threading.Thread(target=_run_role_task, name=f"role-{task_id}", daemon=True)
        with self._lock:
            self._task_threads[task_id] = worker
        worker.start()
        
        print(
            f"ğŸš€ å¯åŠ¨ RLHF è§’è‰²ä»»åŠ¡ '{task_id}' | "
            f"è§’è‰²={config.role} æ¨¡å‹={config.model_size} "
            f"èµ„æº=[CPU:{config.cpu_required}, MEM:{config.memory_required/1024:.1f}GB]"
        )
        return {"success": True, "task_id": task_id}

    def cancel(self, task_id: str) -> dict:
        """åœæ­¢æŒ‡å®šè§’è‰²ä»»åŠ¡ï¼Œä¿å­˜æ£€æŸ¥ç‚¹å¹¶è¿”å›ä»»åŠ¡æ‘˜è¦ã€‚"""
        with self._lock:
            stop_flag = self._stop_flags.get(task_id)
            summary = self._tasks.get(task_id)
            thread = self._task_threads.get(task_id)

        if stop_flag is None or summary is None:
            return {"success": False, "error": f"Task '{task_id}' not found"}

        print(f"â¸ï¸  å–æ¶ˆè§’è‰²ä»»åŠ¡ '{task_id}'ï¼Œä¿å­˜æ£€æŸ¥ç‚¹...")
        stop_flag.set()
        if thread and thread.is_alive():
            thread.join(timeout=2.0)

        with self._lock:
            self._stop_flags.pop(task_id, None)
            self._task_threads.pop(task_id, None)

        summary.setdefault("end_time", time.time())
        summary.setdefault("status", "preempted")
        
        # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
        if summary.get("steps"):
            last_step = len(summary["steps"])
            if last_step not in summary.get("checkpoints", []):
                summary.setdefault("checkpoints", []).append(last_step)
        
        print(
            f"ğŸ’¾ ä»»åŠ¡ '{task_id}' å·²ä¿å­˜æ£€æŸ¥ç‚¹: "
            f"step={len(summary.get('steps', []))} "
            f"checkpoints={summary.get('checkpoints', [])}"
        )
        return {"success": True, "task": summary}

    def role_task_summary(self, task_id: Optional[str] = None) -> dict:
        """è¿”å›æŒ‡å®šä»»åŠ¡æˆ–å…¨éƒ¨ä»»åŠ¡çš„å½“å‰çŠ¶æ€ã€‚"""
        with self._lock:
            if task_id:
                task = self._tasks.get(task_id)
                if task is None:
                    return {"success": False, "error": f"Task '{task_id}' not found"}
                return {
                    "success": True,
                    "task": {
                        **task,
                        "steps": [step.__dict__ for step in task["steps"]],
                    },
                }

            return {
                "success": True,
                "tasks": {
                    tid: {
                        **summary,
                        "steps": [step.__dict__ for step in summary["steps"]],
                    }
                    for tid, summary in self._tasks.items()
                },
            }


def print_stats(scheduler: SimpleScheduler, title: str) -> None:
    """æ‰“å°æŠ¢å ç»Ÿè®¡ä¿¡æ¯"""
    stats = scheduler.stats()
    print(f"\nğŸ“Š {title}")
    print(f"  å½“å‰è¿è¡Œä»»åŠ¡: {stats.get('running_tasks', 0)}")
    print(f"  ç´¯è®¡æŠ¢å æ¬¡æ•°: {stats.get('total_preemptions', 0)}")
    recent = stats.get("recent_preemptions") or []
    if recent:
        print("  æœ€è¿‘æŠ¢å è®°å½•:")
        for record in recent[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3æ¡
            task_id = record.get("task_id", "unknown")
            reason = record.get("reason", "unknown")
            cancel_success = record.get("cancel_success", False)
            print(f"    â€¢ {task_id}: {reason} (å–æ¶ˆæˆåŠŸ={cancel_success})")
    else:
        print("  æœ€è¿‘æŠ¢å è®°å½•: æ— ")


def run_demo() -> None:
    print("=" * 80)
    print("ğŸš€ RLHF è§’è‰²è°ƒåº¦æŠ¢å  Demoï¼ˆä½¿ç”¨ SimpleSchedulerï¼‰")
    print("=" * 80)
    
    # Ray é…ç½®å‚æ•°
    ray_config = {
        "ignore_reinit_error": True,
        "local_mode": True,  # è¿›ç¨‹å†…æ‰§è¡Œï¼Œä¾¿äºè°ƒè¯•
        "num_cpus": 4,       # é™åˆ¶ CPU æ ¸å¿ƒæ•°
        "include_dashboard": False,
        "log_to_driver": False,
    }
    
    # æ™ºèƒ½åˆå§‹åŒ– Ray
    try:
        # å°è¯•è¿æ¥ç°æœ‰é›†ç¾¤
        ray.init(address="auto", ignore_reinit_error=True)
        print("âœ… è¿æ¥åˆ°ç°æœ‰ Ray é›†ç¾¤")
    except Exception:
        # åˆ›å»ºæ–°æœ¬åœ°é›†ç¾¤
        print(f"ğŸ“‹ Ray é…ç½®: {ray_config}")
        ray.init(**ray_config)
    
    # åˆ›å»º SimpleScheduler
    scheduler = SimpleScheduler("simple-rlhf-demo")
    
    try:
        # ===== é…ç½®æŠ¢å ç­–ç•¥ =====
        print("\nğŸ“‹ é…ç½®åŸºäº Label çš„ RLHF è§’è‰²æŠ¢å ç­–ç•¥...")
        scheduler.configure_preemption(
            enable_label_preemption=True,
            label_preemption_rules={
                "role": {
                    # Train è§’è‰²å¯ä»¥æŠ¢å æ‰€æœ‰å…¶ä»–è§’è‰²
                    "train": ["reward", "critic", "rollout"],
                    # Reward å’Œ Critic å¯ä»¥æŠ¢å  Rollout
                    "reward": ["rollout"],
                    "critic": ["rollout"],
                }
            },
            preemption_aggressiveness=PreemptionAggressiveness.MEDIUM,  # ä¸­ç­‰æ¿€è¿›ç¨‹åº¦
            cross_pool_priority_threshold=5.0,
            enable_cross_pool_preemption=True,
        )
        print("âœ… æŠ¢å ç­–ç•¥é…ç½®å®Œæˆ: Train > Reward/Critic > Rollout")

        # ===== åˆ›å»ºèµ„æºæ±  =====
        pool_name = "rlhf-shared-pool"
        print(f"\nğŸ—ï¸  åˆ›å»º RLHF å…±äº«èµ„æºæ± ...")
        pool_result = scheduler.ensure_pool(
            name=pool_name,
            labels={"workload": "rlhf", "tier": "shared"},
            resources={"cpu": 2.0, "memory": 6144.0},  # å¢åŠ åˆ° 6GB ä»¥æ”¯æŒæŠ¢å 
            target_agents=0,  # ä¸é¢„å…ˆåˆ›å»º agentï¼Œç”±ä»»åŠ¡æäº¤æ—¶åˆ›å»º
        )
        
        if pool_result.get("success"):
            print(f"  âœ… {pool_name}: 2 CPU, 6GB Memory")
        else:
            print(f"  âŒ èµ„æºæ± åˆ›å»ºå¤±è´¥: {pool_result.get('error')}")
            return

        # ===== åœºæ™¯ 1ï¼šå¯åŠ¨ Rollout è§’è‰²ä»»åŠ¡ï¼ˆç”Ÿæˆæ ·æœ¬æ•°æ®ï¼‰ =====
        print(f"\n" + "=" * 80)
        print(f"ğŸ“Š åœºæ™¯ 1: å¯åŠ¨ Rollout è§’è‰²ä»»åŠ¡ï¼ˆç”Ÿæˆæ ·æœ¬æ•°æ®ï¼‰")
        print(f"=" * 80)
        
        rollout_task_id = "rollout-data-collection"
        rollout_config = RLHFRoleConfig(
            role="rollout",
            model_size="13B",
            batch_size=24,
            learning_rate=5e-5,
            cpu_required=2.0,
            memory_required=1536.0,  # 1.5GB - å‡å°‘èµ„æºå ç”¨ä»¥ä¾¿æŠ¢å 
        )
        
        print(f"ä»»åŠ¡ ID: {rollout_task_id}")
        print(f"è§’è‰²: {rollout_config.role} - è´Ÿè´£ç”Ÿæˆè®­ç»ƒæ ·æœ¬")
        print(f"æ¨¡å‹è§„æ¨¡: {rollout_config.model_size}")
        print(f"èµ„æºéœ€æ±‚: {rollout_config.cpu_required} CPU, "
              f"{rollout_config.memory_required/1024:.2f} GB Memory")
        
        # ä½¿ç”¨ SimpleScheduler.submit() æäº¤ä»»åŠ¡
        rollout_result = scheduler.submit(
            task_id=rollout_task_id,
            pool=pool_name,
            actor_class=RLHFRoleAgent,
            resources={"cpu": rollout_config.cpu_required, "memory": rollout_config.memory_required},
            priority=5.0,
            labels={
                "job": "rlhf",
                "role": rollout_config.role,
                "model_size": rollout_config.model_size,
            },
            estimated_duration=180.0,  # é¢„ä¼°3åˆ†é’Ÿ
            auto_register=True,  # è‡ªåŠ¨æ³¨å†Œåˆ°æŠ¢å æ§åˆ¶å™¨
        )
        
        if rollout_result.get("success"):
            print(f"âœ… Rollout ä»»åŠ¡æäº¤æˆåŠŸ")
            print(f"   Agent: {rollout_result['agent']['name']}")
            print(f"   Labels: {rollout_config.role}")
            rollout_agent = rollout_result["agent"]["handle"]
            
            # å¯åŠ¨è§’è‰²ä»»åŠ¡
            start_result = ray.get(
                rollout_agent.start_role_task.remote(
                    task_id=rollout_task_id,
                    config=rollout_config,
                    steps=90,
                    step_duration=0.12,
                    checkpoint_interval=15,
                )
            )
            
            if start_result.get("success"):
                print(f"âœ… Rollout è§’è‰²ä»»åŠ¡å·²å¯åŠ¨")
            else:
                print(f"âŒ Rollout è§’è‰²ä»»åŠ¡å¯åŠ¨å¤±è´¥: {start_result.get('error')}")
            
            # éªŒè¯ä»»åŠ¡æ˜¯å¦è¢«æ³¨å†Œåˆ°æŠ¢å æ§åˆ¶å™¨
            time.sleep(0.5)  # ç­‰å¾…æ³¨å†Œå®Œæˆ
            stats = scheduler.stats()
            print(f"   ğŸ“Š å½“å‰è¿è¡Œä»»åŠ¡æ•°: {stats.get('running_tasks', 0)}")
        else:
            print(f"âŒ Rollout ä»»åŠ¡æäº¤å¤±è´¥: {rollout_result.get('error')}")

        print("\nâ³ Rollout è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 3 ç§’è§‚å¯Ÿ...")
        time.sleep(3.0)
        
        print_stats(scheduler, "Rollout ä»»åŠ¡è¿è¡Œåçš„ç»Ÿè®¡")

        # ===== åœºæ™¯ 2ï¼šReward è§’è‰²åˆ°è¾¾ï¼Œè§¦å‘æŠ¢å  =====
        print(f"\n" + "=" * 80)
        print(f"ğŸš¨ åœºæ™¯ 2: Reward è§’è‰²åˆ°è¾¾ï¼Œéœ€è¦èµ„æº")
        print(f"=" * 80)
        
        reward_task_id = "reward-model-eval"
        reward_config = RLHFRoleConfig(
            role="reward",
            model_size="13B",
            batch_size=16,
            learning_rate=1e-4,
            cpu_required=2.0,
            memory_required=1536.0,  # 1.5GB - ä¸ rollout ç›¸åŒä»¥ä¾¿æŠ¢å 
        )
        
        print(f"ä»»åŠ¡ ID: {reward_task_id}")
        print(f"è§’è‰²: {reward_config.role} - è´Ÿè´£è¯„ä¼°æ ·æœ¬è´¨é‡")
        print(f"æ¨¡å‹è§„æ¨¡: {reward_config.model_size}")
        print(f"èµ„æºéœ€æ±‚: {reward_config.cpu_required} CPU, "
              f"{reward_config.memory_required/1024:.2f} GB Memory")
        print(f"\nğŸ’¡ æ ¹æ® label_preemption_rules: reward å¯ä»¥æŠ¢å  rollout")
        
        reward_result = scheduler.submit(
            task_id=reward_task_id,
            pool=pool_name,
            actor_class=RLHFRoleAgent,
            resources={"cpu": reward_config.cpu_required, "memory": reward_config.memory_required},
            priority=5.0,
            labels={
                "job": "rlhf",
                "role": reward_config.role,
                "model_size": reward_config.model_size,
            },
            estimated_duration=120.0,  # é¢„ä¼°2åˆ†é’Ÿ
            auto_register=True,
        )
        
        if reward_result.get("success"):
            print(f"âœ… Reward ä»»åŠ¡æäº¤æˆåŠŸ")
            reward_agent = reward_result["agent"]["handle"]
            
            # å¯åŠ¨è§’è‰²ä»»åŠ¡
            start_result = ray.get(
                reward_agent.start_role_task.remote(
                    task_id=reward_task_id,
                    config=reward_config,
                    steps=80,
                    step_duration=0.14,
                    checkpoint_interval=12,
                )
            )
            
            if start_result.get("success"):
                print(f"âœ… Reward è§’è‰²ä»»åŠ¡å·²å¯åŠ¨")
            else:
                print(f"âŒ Reward è§’è‰²ä»»åŠ¡å¯åŠ¨å¤±è´¥: {start_result.get('error')}")
        else:
            print(f"âŒ Reward ä»»åŠ¡æäº¤å¤±è´¥: {reward_result.get('error')}")
        
        print_stats(scheduler, "Reward ä»»åŠ¡æäº¤åçš„ç»Ÿè®¡")
        
        print("\nâ³ Reward è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 2 ç§’è§‚å¯Ÿ...")
        time.sleep(2.0)

        # å°è¯•æŸ¥çœ‹ Rollout ä»»åŠ¡çŠ¶æ€ï¼ˆå¯èƒ½å·²è¢«æŠ¢å ï¼‰
        if rollout_result.get("success"):
            try:
                rollout_summary = ray.get(
                    rollout_agent.role_task_summary.remote(rollout_task_id)
                )
                if rollout_summary.get("success"):
                    task = rollout_summary["task"]
                    print(f"\nğŸ“¦ Rollout ä»»åŠ¡çŠ¶æ€:")
                    print(f"  çŠ¶æ€: {task['status']}")
                    print(f"  å·²å®Œæˆæ­¥æ•°: {len(task.get('steps', []))}")
                    print(f"  ä¿å­˜çš„æ£€æŸ¥ç‚¹: {task.get('checkpoints', [])}")
            except Exception as e:
                print(f"â„¹ï¸  Rollout ä»»åŠ¡å¯èƒ½å·²è¢«æŠ¢å æ¸…ç†: {e}")

        # ===== åœºæ™¯ 3ï¼šTrain è§’è‰²åˆ°è¾¾ï¼Œè¿›ä¸€æ­¥æŠ¢å  =====
        print(f"\n" + "=" * 80)
        print(f"ğŸ”¥ åœºæ™¯ 3: Train è§’è‰²åˆ°è¾¾ï¼Œéœ€è¦èµ„æº")
        print(f"=" * 80)
        
        train_task_id = "rlhf-train-step"
        train_config = RLHFRoleConfig(
            role="train",
            model_size="7B",
            batch_size=32,
            learning_rate=2e-5,
            cpu_required=2.0,
            memory_required=1536.0,  # 1.5GB - ä¸å…¶ä»–ä»»åŠ¡ç›¸åŒä»¥ä¾¿æŠ¢å 
        )
        
        print(f"ä»»åŠ¡ ID: {train_task_id}")
        print(f"è§’è‰²: {train_config.role} - è´Ÿè´£æ›´æ–°æ¨¡å‹å‚æ•°")
        print(f"æ¨¡å‹è§„æ¨¡: {train_config.model_size}")
        print(f"èµ„æºéœ€æ±‚: {train_config.cpu_required} CPU, "
              f"{train_config.memory_required/1024:.2f} GB Memory")
        print(f"\nğŸ’¡ æ ¹æ® label_preemption_rules: train å¯ä»¥æŠ¢å  reward å’Œ rollout")
        
        train_result = scheduler.submit(
            task_id=train_task_id,
            pool=pool_name,
            actor_class=RLHFRoleAgent,
            resources={"cpu": train_config.cpu_required, "memory": train_config.memory_required},
            priority=5.0,
            labels={
                "job": "rlhf",
                "role": train_config.role,
                "model_size": train_config.model_size,
            },
            estimated_duration=90.0,  # é¢„ä¼°1.5åˆ†é’Ÿ
            auto_register=True,
        )
        
        if train_result.get("success"):
            print(f"âœ… Train ä»»åŠ¡æäº¤æˆåŠŸ")
            train_agent = train_result["agent"]["handle"]
            
            # å¯åŠ¨è§’è‰²ä»»åŠ¡
            start_result = ray.get(
                train_agent.start_role_task.remote(
                    task_id=train_task_id,
                    config=train_config,
                    steps=70,
                    step_duration=0.16,
                    checkpoint_interval=10,
                )
            )
            
            if start_result.get("success"):
                print(f"âœ… Train è§’è‰²ä»»åŠ¡å·²å¯åŠ¨")
            else:
                print(f"âŒ Train è§’è‰²ä»»åŠ¡å¯åŠ¨å¤±è´¥: {start_result.get('error')}")
        else:
            print(f"âŒ Train ä»»åŠ¡æäº¤å¤±è´¥: {train_result.get('error')}")
        
        print_stats(scheduler, "Train ä»»åŠ¡æäº¤åçš„ç»Ÿè®¡")
        
        # å°è¯•æŸ¥çœ‹ Reward ä»»åŠ¡çŠ¶æ€ï¼ˆå¯èƒ½å·²è¢«æŠ¢å ï¼‰
        if reward_result.get("success"):
            try:
                reward_summary = ray.get(
                    reward_agent.role_task_summary.remote(reward_task_id)
                )
                if reward_summary.get("success"):
                    task = reward_summary["task"]
                    print(f"\nğŸ“¦ Reward ä»»åŠ¡çŠ¶æ€:")
                    print(f"  çŠ¶æ€: {task['status']}")
                    print(f"  å·²å®Œæˆæ­¥æ•°: {len(task.get('steps', []))}")
                    print(f"  ä¿å­˜çš„æ£€æŸ¥ç‚¹: {task.get('checkpoints', [])}")
            except Exception as e:
                print(f"â„¹ï¸  Reward ä»»åŠ¡å¯èƒ½å·²è¢« Train æŠ¢å æ¸…ç†: {e}")

        print("\nâ³ Train è§’è‰²è¿è¡Œä¸­ï¼Œç­‰å¾… 3 ç§’è§‚å¯Ÿ...")
        time.sleep(3.0)
        
        # æŸ¥çœ‹ Train ä»»åŠ¡è¿›åº¦
        if train_result.get("success"):
            try:
                train_summary = ray.get(
                    train_agent.role_task_summary.remote(train_task_id)
                )
                if train_summary.get("success"):
                    task = train_summary["task"]
                    steps = task.get("steps", [])
                    if steps:
                        latest = steps[-1]
                        print(f"\nğŸ“Š Train è§’è‰²æœ€æ–°è¿›åº¦:")
                        print(f"  çŠ¶æ€: {task.get('status')}")
                        print(f"  å®Œæˆæ­¥æ•°: {len(steps)}")
                        print(f"  metric_value: {latest.get('metric_value', 0):.4f}")
                        print(f"  loss: {latest.get('loss', 0):.4f}")
                        print(f"  ååé‡: {latest.get('throughput', 0):.0f} tokens/s")
                        print(f"  èµ„æºåˆ©ç”¨ç‡: {latest.get('resource_utilization', 0):.2%}")
            except Exception as e:
                print(f"âš ï¸  Train ä»»åŠ¡è¿›åº¦æŸ¥è¯¢å¤±è´¥: {e}")
        
        # ===== æ€»ç»“ =====
        print(f"\n" + "=" * 80)
        print(f"ğŸ“ˆ Demo æ€»ç»“")
        print(f"=" * 80)
        print(f"âœ“ ä½¿ç”¨ SimpleScheduler API ç®€åŒ–ä»»åŠ¡æäº¤æµç¨‹")
        print(f"âœ“ é€šè¿‡ ensure_pool() åˆ›å»ºèµ„æºæ± ")
        print(f"âœ“ é€šè¿‡ submit() æäº¤ä»»åŠ¡ï¼Œè‡ªåŠ¨å¤„ç†æ³¨å†Œå’ŒæŠ¢å ")
        print(f"âœ“ é€šè¿‡ configure_preemption() é…ç½®åŸºäº label çš„æŠ¢å è§„åˆ™")
        print(f"âœ“ Rollout è§’è‰²é¦–å…ˆå ç”¨èµ„æºæ± ")
        print(f"âœ“ Reward è§’è‰²æ ¹æ® role label è‡ªåŠ¨æŠ¢å  Rollout ä»»åŠ¡")
        print(f"âœ“ Train è§’è‰²è¿›ä¸€æ­¥æŠ¢å  Reward å¹¶ç»§ç»­è®­ç»ƒ")
        print(f"âœ“ æ‰€æœ‰è¢«æŠ¢å ä»»åŠ¡è‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹")
        print(f"\nğŸ’¡ æ ¸å¿ƒä¼˜åŠ¿:")
        print(f"   - SimpleScheduler æä¾›æ›´ç®€æ´çš„ API")
        print(f"   - auto_register=True è‡ªåŠ¨å¤„ç†ä»»åŠ¡æ³¨å†Œ")
        print(f"   - æ— éœ€æ‰‹åŠ¨ç®¡ç† supervisor å’Œåº•å±‚è°ƒåº¦ç»†èŠ‚")
        print(f"   - åŸºäºè¯­ä¹‰çš„ label æŠ¢å è§„åˆ™ï¼Œæ˜“äºç†è§£å’Œé…ç½®")
        
        print_stats(scheduler, "æœ€ç»ˆç»Ÿè®¡æ•°æ®")

    finally:
        print("\nğŸ§¹ æ¸…ç† Scheduler å’Œ Ray")
        scheduler.shutdown()
        ray.shutdown()


if __name__ == "__main__":
    run_demo()

